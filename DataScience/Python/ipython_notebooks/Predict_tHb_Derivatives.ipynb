{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import assessmentModule as amod\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.signal as ss\n",
    "%matplotlib qt\n",
    "\"\"\"\n",
    "For a subset of running LT assessments, look at relationships\n",
    "between SmO2, tHb, and HR using change in slope.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "__author__ = 'Todd Minehardt'\n",
    "\n",
    "\n",
    "# Define working directory where Matlab files are and output directory.\n",
    "data_dir = '/Users/todd/data/WARMUP/RUN'\n",
    "out_dir = '/Users/todd/data/WARMUP/RUN/derivatives'\n",
    "\n",
    "# Go to working directory.\n",
    "os.chdir(data_dir)\n",
    "\n",
    "# Get list of LT assessment IDs from list.\n",
    "aid_file = '/Users/todd/code/AnalysisTools/config/subset_runs_score_16-18.txt'\n",
    "with open(aid_file, 'r') as fn:\n",
    "    aid_list = []\n",
    "    for line in fn:\n",
    "        aid_list.append(line)\n",
    "assessment_ids = [i.strip('\\n') for i in aid_list]\n",
    "\n",
    "# Build a dict keyed on assessment ID, containing all information\n",
    "# from relevant Matlab files. This returns a dict of dicts.\n",
    "data = {}\n",
    "for assess_id in assessment_ids:\n",
    "    data[assess_id] = amod.getMatlabData(assess_id + '_process.mat')\n",
    "    data[assess_id].update(amod.getMatlabData(assess_id + '_sweep.mat'))\n",
    "\n",
    "# Filter data with Savitsky-Golay.\n",
    "def returnSGFilteredData(x, window_length, polyorder, deriv):\n",
    "    \"\"\"Given x, window size, and polynomial order, return\n",
    "    Savitsky-Golay filtered data.\n",
    "    \"\"\"\n",
    "    return ss.savgol_filter(x.flatten(), \n",
    "                            window_length=window_length,\n",
    "                            polyorder=polyorder,\n",
    "                            deriv=deriv)\n",
    "\n",
    "def smooth(x, n):\n",
    "    \"\"\"Return moving average for period n.\"\"\"\n",
    "    w = np.ones((n, )) / n\n",
    "    return np.convolve(x, w, mode='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define start and end indices for data arrays.\n",
    "start_idx = 161\n",
    "end_idx = None\n",
    "to_show = ['56470b06adac18e1278b4586',\n",
    "              '564a1f52adac183f568b456e',\n",
    "              '564e180b07c51979098b4573',\n",
    "              '566047c6adac18097d8b4568',\n",
    "              '566d4502adac1812528b4569',\n",
    "              '5676ca9207c51951518b4568',\n",
    "              '5678384c07c519b85b8b456a',\n",
    "              '568006b8adac1834758b456a',\n",
    "              '568aab2fadac183f618b4568']\n",
    "# Plot remaining assessments.\n",
    "for assess_id in data.keys():\n",
    "#for assess_id in to_show:\n",
    "    \n",
    "    if 'HR' in data[assess_id]['process'].keys():\n",
    "        HR = data[assess_id]['process']['HR']\n",
    "    elif 'HR' in data[assess_id]['sweep'].keys():\n",
    "        HR = data[assess_id]['sweep']['HR']\n",
    "    \n",
    "    if 'SmO2' in data[assess_id]['process'].keys():\n",
    "        SmO2 = data[assess_id]['process']['SmO2']\n",
    "    elif 'SmO2' in data[assess_id]['sweep'].keys():\n",
    "        SmO2 = data[assess_id]['sweep']['SmO2']\n",
    "        \n",
    "    if 'tHb' in data[assess_id]['process'].keys():     \n",
    "        tHb = data[assess_id]['process']['tHb']\n",
    "    \n",
    "    # Truncate arrays on start and end indices.\n",
    "    HR = HR[start_idx:end_idx]\n",
    "    SmO2 = SmO2[start_idx:end_idx]\n",
    "    tHb = tHb[start_idx:end_idx]\n",
    "    \n",
    "    # Three subplots sharing x axis\n",
    "    f, (ax1, ax2, ax3) = plt.subplots(3, sharex=True, sharey=False)\n",
    "    \n",
    "    # Plot the polynomial fit for HR.\n",
    "    idx = np.isfinite(HR)\n",
    "    y = HR[idx]\n",
    "    x = np.arange(len(y))\n",
    "    z = np.polyfit(x, y, deg=4)\n",
    "    fit = np.polyval(z, np.arange(len(HR)))\n",
    "    \n",
    "    x_time_ticks = np.arange(len(fit)) / 5\n",
    "    ax1.plot(x_time_ticks, \n",
    "             fit, \n",
    "             color='red',\n",
    "             label='HR fit')\n",
    "        \n",
    "    ax1.plot(x_time_ticks, \n",
    "             HR, \n",
    "             color='red',\n",
    "             label='HR')\n",
    "\n",
    "    ax1.set_ylim(np.nanmin(HR), \n",
    "                 np.nanmax(HR))\n",
    "    ax1.set_ylabel('HR (bpm)',\n",
    "                   color='red')\n",
    "    for tl in ax1.get_yticklabels():\n",
    "        tl.set_color('red')   \n",
    "    ax1.set_title('Assessment ' + assess_id)\n",
    "    \n",
    "    ax1.minorticks_on()\n",
    "    ax1.xaxis.grid(True, which='major')\n",
    "    ax1.xaxis.grid(True, which='minor')\n",
    "    ax1.yaxis.grid(True, which='major')\n",
    "    ax1.yaxis.grid(False, which='minor')\n",
    "    ax1.tick_params(axis='y', which='minor', left='off')\n",
    "    #ax1.set_xlim(0, 3600)\n",
    "    \n",
    "    # Plot the polynomial fit for SmO2.\n",
    "    idx = np.isfinite(SmO2)\n",
    "    y = SmO2[idx]\n",
    "    x = np.arange(len(y))\n",
    "    z = np.polyfit(x, y, deg=4)\n",
    "    fit = np.polyval(z, np.arange(len(SmO2)))\n",
    "    x_time_ticks = np.arange(len(fit)) / 5\n",
    "    \n",
    "    ax2.plot(x_time_ticks,\n",
    "             fit,\n",
    "             color='green',\n",
    "             label='SmO2 fit')\n",
    "    ax2.plot(x_time_ticks,\n",
    "             SmO2,\n",
    "             color='green',\n",
    "             label='SmO2',\n",
    "             alpha=0.25)\n",
    "    ax2.set_ylim(np.nanmin(SmO2), \n",
    "                 np.nanmax(SmO2))\n",
    "    ax2.set_ylabel('SmO2 (%)',\n",
    "                   color='green')\n",
    "    for tl in ax2.get_yticklabels():\n",
    "        tl.set_color('green')\n",
    "        \n",
    "    ax2.minorticks_on()\n",
    "    ax2.xaxis.grid(True, which='major')\n",
    "    ax2.xaxis.grid(True, which='minor')\n",
    "    ax2.yaxis.grid(True, which='major')\n",
    "    ax2.yaxis.grid(False, which='minor')\n",
    "    ax2.tick_params(axis='y', which='minor', left='off')\n",
    "    #ax2.set_xlim(0, 3600)\n",
    "    \n",
    "    # Find local maximum from end of stage 1 to stage 8.\n",
    "    local_max = start_idx + np.argmax(fit[900:7200]) / 5\n",
    "    ax2.axvline(local_max, \n",
    "                color='green',\n",
    "                linewidth=3,\n",
    "                label=local_max)\n",
    "    ax2.legend()\n",
    "        \n",
    "    # Plot the polynomial fit for tHb.\n",
    "    idx = np.isfinite(tHb)\n",
    "    y = tHb[idx]\n",
    "    x = np.arange(len(y))\n",
    "    z = np.polyfit(x, y, deg=4)\n",
    "    fit = np.polyval(z, np.arange(len(tHb)))\n",
    "    \n",
    "    x_time_ticks = np.arange(len(fit)) / 5\n",
    "    ax3.plot(x_time_ticks,\n",
    "             fit,\n",
    "             color='blue',\n",
    "             label='tHb fit')\n",
    "    ax3.plot(x_time_ticks,\n",
    "             tHb,\n",
    "             color='blue',\n",
    "             label='tHb',\n",
    "             alpha=0.25)\n",
    "    ax3.set_ylim(np.nanmin(tHb),\n",
    "                 np.nanmax(tHb))\n",
    "    ax3.set_ylabel('tHb fit (g/dL)',\n",
    "                   color='blue')\n",
    "\n",
    "    for tl in ax3.get_yticklabels():\n",
    "        tl.set_color('blue')\n",
    "    ax3.set_xlabel('time (s)')\n",
    "    \n",
    "    ax3.minorticks_on()\n",
    "    ax3.xaxis.grid(True, which='major')\n",
    "    ax3.xaxis.grid(True, which='minor')\n",
    "    ax3.yaxis.grid(True, which='major')\n",
    "    ax3.yaxis.grid(False, which='minor')\n",
    "    ax3.tick_params(axis='y', which='minor', left='off')\n",
    "    #ax3.set_xlim(0, 3600)\n",
    "    \n",
    "    # Find local maximum from end of stage 1 to stage 8.\n",
    "    local_max = start_idx + np.argmax(fit[900:7200]) / 5\n",
    "    ax3.axvline(local_max, \n",
    "                color='blue',\n",
    "                linewidth=3,\n",
    "                label=local_max)\n",
    "    ax3.legend()\n",
    "\n",
    "    \n",
    "    # Fine-tune figure; make subplots close to each other and hide x ticks for\n",
    "    # all but bottom plot.\n",
    "    f.subplots_adjust(hspace=0)\n",
    "    plt.setp([a.get_xticklabels() for a in f.axes[:-1]], visible=False)\n",
    "\n",
    "    # Plot parameters.\n",
    "    plt.rcParams['figure.figsize'] = 10, 8\n",
    "    plt.rcParams['legend.loc'] = 'best'\n",
    "    out_file = os.path.join(out_dir, assess_id + '.png')\n",
    "    plt.savefig(out_file)\n",
    "    plt.close()\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exercise_times = []\n",
    "for aid in assessment_ids:\n",
    "    time = int(data[aid]['sweep']['time'][-1])\n",
    "    exercise_times.append([aid, time])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(exercise_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "491\n",
      "2238\n",
      "154\n",
      "1041\n",
      "154\n",
      "664\n",
      "870\n",
      "523\n",
      "710\n",
      "125\n",
      "2282\n",
      "2452\n",
      "2214\n",
      "2385\n",
      "2059\n",
      "543\n",
      "2214\n",
      "543\n",
      "814\n",
      "2378\n",
      "2368\n",
      "2458\n",
      "1015\n",
      "2547\n",
      "2385\n",
      "374\n",
      "2442\n",
      "43\n",
      "646\n",
      "408\n",
      "2445\n",
      "834\n",
      "2506\n",
      "2522\n",
      "2506\n",
      "2293\n",
      "2575\n",
      "567\n",
      "554\n",
      "2558\n",
      "2672\n",
      "2690\n",
      "1015\n",
      "2482\n",
      "2366\n",
      "2072\n",
      "1808\n",
      "2693\n",
      "2654\n",
      "2293\n",
      "2647\n",
      "1999\n",
      "2738\n",
      "2647\n",
      "2766\n",
      "342\n",
      "611\n",
      "2674\n",
      "2732\n",
      "2735\n",
      "237\n",
      "2629\n",
      "680\n",
      "2673\n",
      "2408\n",
      "1785\n",
      "2758\n",
      "2886\n",
      "411\n",
      "2929\n",
      "2068\n",
      "2841\n",
      "2789\n",
      "1256\n",
      "2322\n",
      "333\n",
      "2878\n",
      "2967\n",
      "2912\n",
      "2680\n",
      "2895\n",
      "688\n",
      "1630\n",
      "1306\n",
      "2979\n",
      "2960\n",
      "3001\n",
      "2991\n",
      "2973\n",
      "2973\n",
      "3035\n"
     ]
    }
   ],
   "source": [
    "users = []\n",
    "for i in assessment_ids:\n",
    "    uid = data[i]['assessment']['user_id']\n",
    "    if uid.shape[0] == 0:\n",
    "        uid = 99999\n",
    "    elif uid.shape[0] == 1:\n",
    "        uid = np.asscalar(uid)\n",
    "    print(uid)\n",
    "    users.append(uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.324608"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asscalar(data['56470b06adac18e1278b4586']['assessment']['stage_at_lt_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['completed_on', 'lthr', 'allow_download', 'completed_stages', 'calculated_lt1_speed', 'protocol', 'days_per_week', 'alpha__id', 'calculated_lt_speed', 'created_at', 'entry_type', 'months_training', 'links', 'sport', 'training_zones', 'status', 'stage_at_lt', 'duration', 'worker_details', 'user_id', 'stage_at_lt_value', 'distance_per_week', 'lt1hr'])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['56470b06adac18e1278b4586']['assessment'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1015',\n",
       " '1015',\n",
       " '1041',\n",
       " '125',\n",
       " '1256',\n",
       " '1306',\n",
       " '154',\n",
       " '154',\n",
       " '1630',\n",
       " '1785',\n",
       " '1808',\n",
       " '1999',\n",
       " '2059',\n",
       " '2068',\n",
       " '2072',\n",
       " '2214',\n",
       " '2214',\n",
       " '2238',\n",
       " '2282',\n",
       " '2293',\n",
       " '2293',\n",
       " '2322',\n",
       " '2366',\n",
       " '2368',\n",
       " '237',\n",
       " '2378',\n",
       " '2385',\n",
       " '2385',\n",
       " '2408',\n",
       " '2442',\n",
       " '2445',\n",
       " '2452',\n",
       " '2458',\n",
       " '2482',\n",
       " '2506',\n",
       " '2506',\n",
       " '2522',\n",
       " '2547',\n",
       " '2558',\n",
       " '2575',\n",
       " '2629',\n",
       " '2647',\n",
       " '2647',\n",
       " '2654',\n",
       " '2672',\n",
       " '2673',\n",
       " '2674',\n",
       " '2680',\n",
       " '2690',\n",
       " '2693',\n",
       " '2732',\n",
       " '2735',\n",
       " '2738',\n",
       " '2758',\n",
       " '2766',\n",
       " '2789',\n",
       " '2841',\n",
       " '2878',\n",
       " '2886',\n",
       " '2895',\n",
       " '2912',\n",
       " '2929',\n",
       " '2960',\n",
       " '2967',\n",
       " '2973',\n",
       " '2973',\n",
       " '2979',\n",
       " '2991',\n",
       " '3001',\n",
       " '3035',\n",
       " '333',\n",
       " '342',\n",
       " '374',\n",
       " '408',\n",
       " '411',\n",
       " '43',\n",
       " '491',\n",
       " '523',\n",
       " '543',\n",
       " '543',\n",
       " '554',\n",
       " '567',\n",
       " '611',\n",
       " '646',\n",
       " '664',\n",
       " '680',\n",
       " '688',\n",
       " '710',\n",
       " '814',\n",
       " '834',\n",
       " '870']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
